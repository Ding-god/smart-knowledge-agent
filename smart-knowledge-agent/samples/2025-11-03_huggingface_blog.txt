ğŸ¤— Hugging Face Blog æœ€æ–° 5 ç¯‡æ–‡ç«  (2025-11-03)

### 1. NEWä½ ä¹Ÿå¯ä»¥é˜…è¯»è¿™ç¯‡åšå®¢çš„ä¸­æ–‡ç‰ˆ
é“¾æ¥: https://huggingface.co/blog/zh
æ‘˜è¦: æ— æ‘˜è¦ï¼ˆè¯·ç‚¹å‡»é˜…è¯»å…¨æ–‡ï¼‰

### 2. view all
é“¾æ¥: https://huggingface.co/blog/community
æ‘˜è¦: æ— æ‘˜è¦ï¼ˆè¯·ç‚¹å‡»é˜…è¯»å…¨æ–‡ï¼‰

### 3. Granite 4.0 Nano: Just how small can you go?Byibm-graniteand 1 otherâ€¢6 days agoâ€¢96
é“¾æ¥: https://huggingface.co/blog/ibm-granite/granite-4-nano
æ‘˜è¦: Today we are excited to share Granite 4.0 Nano , our smallest models yet, released as part of IBM's Granite 4.0 model family.  Designed for the edge and on-device applications, these models demonstrate excellent performance for their size and represent IBM's continued commitment to develop powerful, useful, models that don't require hundreds of billions of parameters to get the job done.
Like all Granite 4.0 models , the Nano models are released under an Apache 2.0 license with native architecture support on popular runtimes like vLLM, llama.cpp, and MLX. The models were trained with the same improved training methodologies, pipelines, and over 15T tokens of training data developed for the original Granite 4.0 models. This release includes variants benefiting from the Granite 4.0â€™s new, efficient hybrid architecture , and like all Granite language models, the Granite 4.0 Nano models also carry with them IBM's ISO 42001 certification for responsible model development, giving users added confidence that models are built and governed to global standards.

### 4. Why Did MiniMax M2 End Up as a Full Attention Model?ByMiniMax-AIâ€¢4 days agoâ€¢37
é“¾æ¥: https://huggingface.co/blog/MiniMax-AI/why-did-m2-end-up-as-a-full-attention-model
æ‘˜è¦: After M2 release, weâ€™ve been receiving many queries from the community on â€œWhy did you turn back the clock and go with full attention with MiniMax M2?â€ We could give the textbook debate â€” spend an afternoon explaining why you should build linear or sparse attention, then another afternoon explaining why you shouldnâ€™t. But at the end of the day, all that theory only goes so far. The real question is simple: should you actually do it?
So, let's start with the conclusion: We are always working on it. But in a real-world, industrial-grade system, the truth is that efficient attention still has some way to go before it can definitively beat full attention. As LLMs have evolved, the entire stack has become monstrously complex. We serve more scenarios, and the architecture design trade-offs are exploding: "How does it perform on code and math? What about agent scenarios? How does it handle multimodality? Does long-chain CoT still hold up? Can RL scale on top of it? Are there hidden traps with low-precision compute? How do you implement interleaved thinking, caching, or speculative decoding? ... "

### 5. The Worldâ€™s First and Best Speed Painting SoftwareBywang12390â€¢5 days agoâ€¢27
é“¾æ¥: https://huggingface.co/blog/wang12390/speed-painting-software
æ‘˜è¦: Introduction: A New Era of Digital Creativity What Is Miragic.AI? Why Miragic.AI Is the First of Its Kind 1. AI-Powered Real-Time Rendering 2. Adaptive Artistic Styles 3. Speed Without Complexity 4. Instant Color and Lighting Suggestions 5. Smart Background Generation How Miragic.AI Revolutionizes Speed Painting 1. Instant Brush-to-Scene Conversion 2. One-Stroke Realism 3. Smart Brush Caching 4. Real-Time Co-Creation 5. Seamless Cloud Collaboration Key Features That Make Miragic.AI Unbeatable Why Artists and Designers Love Miragic.AI 1. 10x Faster Workflows 2. Human + AI Harmony 3. Perfect for Professionals and Beginners 4. Limitless Creativity 5. Future-Proof Workflow The Vision Behind Miragic.AI For decades, artists have sought tools that bridge imagination and expression, making Speed Painting a reality with software like Miragic.
For decades, artists have searched for tools that could bridge the gap between imagination and expression â€” software that not only keeps up with creativity but accelerates it. Traditional digital painting tools like Photoshop, Krita, and Procreate have transformed the way artists work, but they still rely heavily on manual effort, repetitive steps, and time-consuming layer management.
